{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "pd.options.mode.chained_assignment = None  # default='warn', Mutes warnings when copying a slice from a DataFrame.\n",
    "pd.set_option('display.max_columns', None)\n",
    "import glob\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling and loading the data\n",
    "For this exploratory analysis we used the Spark cluster to randomly sample the data with the `sample_data.py` script and retrieved the metadata entries for the items that appear in our samples by writing the product IDs to a text file one per line and using the `get_metadata.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to the data and metadata folders.\n",
    "DATA_FOLDER = 'data/'\n",
    "META_FOLDER = DATA_FOLDER + 'meta/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load one data file\n",
    "def load_one_file(path):\n",
    "    with open(path) as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "# Load one metadata file. The rows aren't proper JSON\n",
    "# but they can be parsed using python's eval function\n",
    "# as per the dataset's web page.\n",
    "def load_one_meta_file(path):\n",
    "    with open(path) as f:\n",
    "        return [eval(line) for line in f]\n",
    "\n",
    "# The sample we extracted is still too large, so we'll only use the first 100 files\n",
    "data_files = glob.glob(DATA_FOLDER + 'part-000*')\n",
    "data = sum(map(load_one_file, data_files), [])\n",
    "\n",
    "# Create the first dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the product IDs to a .csv files, one per line.\n",
    "# Used to get metadata using the cluster.\n",
    "# df[['asin']].to_csv('asin_lookup.csv', index=False, header=False)\n",
    "\n",
    "# The meta folder contains metadata for all the items we were interested in.\n",
    "meta_files = glob.glob(META_FOLDER + '*')\n",
    "meta = sum(map(load_one_meta_file, meta_files), [])\n",
    "\n",
    "# Create the second dataframe\n",
    "meta_df = pd.DataFrame(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the dataframes. Since our analysis relies on the metadata for a good part\n",
    "# we have to remove any reviews for which metadata is not available.\n",
    "joined = pd.merge(df, meta_df, how='inner')\n",
    "\n",
    "# Parse the review time as a DateTime and add review month and year columns\n",
    "joined['reviewTime'] = pd.to_datetime(joined.unixReviewTime, unit='s')\n",
    "joined['reviewMonth'] = joined.reviewTime.map(lambda t: t.month)\n",
    "joined['reviewYear'] = joined.reviewTime.map(lambda t: t.year)\n",
    "\n",
    "# We don't want any reviews for which the price is either NaN or 0\n",
    "# or which don't belong to any category\n",
    "joined = joined.dropna(axis=0, subset=['categories', 'price', 'reviewText'])\n",
    "joined = joined[joined.price != 0 & (len(joined.reviewText) > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features\n",
    "#### Sentiment scores\n",
    "Thre are several options to do sentiment analysis: clustering, training a classifier on an existing corpus of labeled data or using a pre-trained one. We used [VADER](https://github.com/cjhutto/vaderSentiment), a pre-trained sentiment score analyzer tuned for messages that tipically appear on social media to give each review text a series of sentiment scores. The reasons behind our choice are that training a classifirer is time consuming and that VADER is trained on text snippets similar to those in our dataset, including some from Amazon reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So creative and funny. Loved the many twists and turns of this story and the clever way in which the author wove history into the craziness that was this man's life!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compound': 0.899, 'neg': 0.062, 'neu': 0.617, 'pos': 0.321}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example\n",
    "print(joined.iloc[10]['reviewText'])\n",
    "analyzer.polarity_scores(joined.iloc[10]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the sentiment score columns to the dataframe\n",
    "comp_score = joined.reviewText.apply(lambda t: analyzer.polarity_scores(t))\n",
    "joined['compound_score'] = comp_score.apply(lambda s: s['compound'])\n",
    "joined['positive_score'] = comp_score.apply(lambda s: s['pos'])\n",
    "joined['negative_score'] = comp_score.apply(lambda s: s['neg'])\n",
    "joined['neutral_score'] = comp_score.apply(lambda s: s['neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each non-empty sales rank is a dictionary that maps exactly one\n",
    "# category to exactly one ranking\n",
    "joined['salesRankPosition'] = joined.salesRank.apply(lambda r: list(r.values())[0]\n",
    "                                                     if r and isinstance(r, dict) else np.nan)\n",
    "joined['salesRankCategory'] = joined.salesRank.apply(lambda r: list(r.keys())[0]\n",
    "                                                     if r and isinstance(r, dict) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word counts\n",
    "We measured the number of words that make up a review as an indicator of the review's complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Add tokenized text and word cound to the dataframe\n",
    "joined['tokenized_text'] = joined.reviewText.apply(tokenizer.tokenize)\n",
    "joined['word_count'] = joined.tokenized_text.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main category\n",
    "Each item in the dataset has a `categories` field which, when not absent, is an array of arrays of strings. Each item can belong to an arbitrary number of categories some of which are subcategories of a larger category. We will first flatten these arrays of arrays in order to make subsequent processing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten the categories\n",
    "joined['categories_flat'] = joined.categories.apply(lambda a: [i for sa in a for i in sa])\n",
    "# Remove rows with no categories\n",
    "joined = joined[[(c and bool(c[0])) for c in joined.categories_flat]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to plot aggregate values for each category we need to pick one category for each product that we will use as its main category. We built a dictionary that maps the most common categories to the main category and assigned a main category to each item according to which of these common categories it belongs to. In order to build this dictionary we started from the list of categories that the maintainer of the dataset offers separate files for and added more until we could cover almost all the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load category dictionary from file\n",
    "categories_dict = None\n",
    "with open('categories_dict.json') as f:\n",
    "    categories_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that returns an item's main category according\n",
    "# to the above dictionary, or NaN if none of its categories appear in the dictionary.\n",
    "def get_main_category(categories):\n",
    "    for c in categories:\n",
    "        if c in categories_dict:\n",
    "            return categories_dict[c]\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "# Derive each product's main category\n",
    "joined['main_category'] = joined.categories_flat.apply(lambda a: get_main_category(a))\n",
    "\n",
    "# Remove items for which there is no category\n",
    "joined = joined.dropna(axis=0, subset=['main_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this is not explained in the dataset's documentation we can see that in all but one review the second element of the `helpful` field is greater or equal than the first. Thus we assume that the first element is the number of users that rated the review as helpful and the second one is the total number of ratings that the review received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of times that the review was voted as helpful\n",
    "joined['helpful_pos'] = joined.helpful.apply(lambda a: a[0])\n",
    "\n",
    "# Total number of votes that the review received\n",
    "joined['helpful_tot'] = joined.helpful.apply(lambda a: a[1])\n",
    "\n",
    "# Ratio of helpful votes to total votes\n",
    "joined['helpful_ratio'] = joined.helpful.apply(lambda a: a[0] / a[1] if a[1] else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the prices in tiers to run some of the comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arbitrarily chosen\n",
    "price_bins = [\n",
    "    0,\n",
    "    10,\n",
    "    20,\n",
    "    30,\n",
    "    40,\n",
    "    50,\n",
    "    60,\n",
    "    70,\n",
    "    80,\n",
    "    90,\n",
    "    100,\n",
    "    200,\n",
    "    500,\n",
    "    1000\n",
    "]\n",
    "\n",
    "joined['price_tier'] = pd.cut(joined.price, price_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final dataframe\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how many reviews are left\n",
    "print('Remaining reviews: {}'.format(joined.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error bars with bootstrap resampling\n",
    "When plotting aggregate statistics for a group, such as the mean score, we need to include error bars in the plot. We used bootstrap resampling to derive confidence intervals for those statistics since the underlying distribution of the data is unknown to us in general.\n",
    "\n",
    "All the error bars that we used in our analysis are 95% confidence intervals obtained using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_estimate(data, func):\n",
    "    \"\"\"Calculate a bootstrap estimate of a certain function of a sequence\n",
    "    This function draws a random sample with replacement from a list and\n",
    "    uses func to calculate a statistic over that sample.\n",
    "    Since the sample is drawn with replacement each element of the list\n",
    "    may appear multiple times or not appear at all in the sample.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # Generate n random indices with replacement\n",
    "    indices = np.random.randint(n, size=n)\n",
    "    \n",
    "    # Sample the data\n",
    "    sample = data.iloc[indices]\n",
    "\n",
    "    # Compute the statistic\n",
    "    return func(sample)\n",
    "\n",
    "def confidence_interval(data, count, func, confidence=0.95):\n",
    "    \"\"\"Return a statistic and its confidence interval of a sequence using bootstrap resampling.\n",
    "    Computes the statistic over count bootstrap samples drawn from the data, then computes the \n",
    "    lower and uppper bounds of the confidence interval.\n",
    "    \"\"\"\n",
    "    estimates = [bootstrap_estimate(data, func) for _ in range(count)]\n",
    "    \n",
    "    # Debug: verify that the estimates have a normal distribution\n",
    "    # plt.hist(estimates, bins=50)\n",
    "    \n",
    "    # Calculate the confidence interval bounds assuming a normal distribution in\n",
    "    # the estimates\n",
    "    m, se = np.mean(estimates), np.std(estimates)\n",
    "    lower, upper = scipy.stats.norm.interval(confidence, loc=m, scale=se)\n",
    "    \n",
    "    return m, lower, upper\n",
    "\n",
    "def plot_groupby_error_bars(grouped, count, func, ax, confidence=0.95):\n",
    "    \"\"\"Plot a bar plot showing the result of a statistic applied to the groups\n",
    "    of a groupby object and use count bootstrap samples to compute confidence intervals\n",
    "    \"\"\"\n",
    "    out = grouped.agg(lambda a: confidence_interval(a, count, func, confidence))\n",
    "    means = out.apply(lambda x: x[0] if x else 0)\n",
    "    mins = out.apply(lambda x: x[1] - x[0] if x else 0)\n",
    "    maxs = out.apply(lambda x: x[2] - x[0] if x else 0)\n",
    "\n",
    "    errs = np.c_[mins, maxs].T\n",
    "    means.plot(kind='bar', ax=ax, yerr=errs, ecolor='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: 95% confidence interval of the mean of the review scores with\n",
    "# 1000 bootstrap samples. \n",
    "confidence_interval(joined.overall, 1000, np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature analysis\n",
    "We can now start to have a look at the distribution of the various features. First of all: overall score distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Overall distribution\n",
    "joined.overall.value_counts().plot(kind='pie', title='Distribution of review scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distribution with respect to price\n",
    "_, ax1 = plt.subplots(1, 1, figsize=(16,5))\n",
    "ax1.set_title('Review distribution at different prices')\n",
    "ax1.set_xlabel('Price')\n",
    "\n",
    "# Divide the reviews in uniformly sized bins according to the item's price\n",
    "bins = np.linspace(0, 1000, 12)\n",
    "gb = joined.groupby('overall')\n",
    "series = np.array([np.histogram(gb.get_group(i).price.values, bins=bins)[0] for i in range(1, 6)])\n",
    "\n",
    "# Make the total height of the bars equal 1\n",
    "series = series / series.sum(axis=0)\n",
    "histbins = bins[:-1] + np.ediff1d(bins) / 2\n",
    "bottom = np.zeros(series.shape[1])\n",
    "\n",
    "for i in range(series.shape[0]):\n",
    "    ax1.bar(histbins, series[i], width=50, bottom=bottom)\n",
    "    bottom += series[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that more than half of the reviews gave five stars to the product independently of the price. The low proportion of 1 and 2 star reviews suggests that customers are very likely to be satisfied with the product they purchased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now consider the number of reviews by month of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(12,5))\n",
    "joined.reviewMonth.value_counts().sort_index().plot(ax=ax, kind='bar', title='Review distribution by month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of reviews seems to be highest during winter and spring and lower during autumn, with January being the month with the highest number of reviews. The biggest shopping time in the year is during the christmas holidays and we imagine that reviews are written the next month after the product has been used for some time.\n",
    "\n",
    "We can now start looking at the prices of the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group the items by price tier\n",
    "group_by_price_tier = joined.groupby('price_tier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we can plot the distribution of the prices of reviewed items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(13,5))\n",
    "ax.set_title('Review distribution by price')\n",
    "joined.price.hist(bins=50, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution seems to be heavy tailed, with very cheap items making up the majority of the reviews. We can verify if this distribution follows a power law by plotting it on a log-log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to make logarithmic bins ourselves.\n",
    "# _, ax = plt.subplots(figsize=(13,5))\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_title('Review distribution by price')\n",
    "# joined.price.hist(ax=ax, log=True, bins=log_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution doesn't follow a linear relationship on a log-log plot so the distribution is not a power law.\n",
    "\n",
    "Now let's see the distribution according to the price tiers we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(13,5))\n",
    "\n",
    "ax.set_title('Review distribution by price tier')\n",
    "\n",
    "group_by_price_tier.size().plot(kind='bar', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the hypotheses we want to verify is whether the price of an item correlates with its review score, more specifically whether items belonging to a higher price tier are more likely to get better reviews. We can verify that by computing the mean review score for each price tier and displaying that on a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(13,5))\n",
    "\n",
    "ax.set_title('Average review score by price tier')\n",
    "\n",
    "plot_groupby_error_bars(group_by_price_tier.overall, 1000, np.mean, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be no correlation between an item's price tier and its mean score. We did not look at the medians since more than half of the reviews give 5 stars to the item in all price tiers and thus the median would always be 5.\n",
    "\n",
    "We can also verify whether the month during which a review was written correlates with its score. The presence of such a correlation could indicate that buyers are more likely to give a better review in certain periods of the year than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group data by the month in which the review was written.\n",
    "group_by_month = joined.groupby('reviewMonth')\n",
    "overall_month = group_by_month.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(13,5))\n",
    "ax.set_title('Average review score by month')\n",
    "\n",
    "plot_groupby_error_bars(overall_month, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that the correlation we hypothesized does not exist in the data. The review scores seem to be independent of the month in which they were written.\n",
    "\n",
    "Let's now look at the items grouped by their category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(13,5))\n",
    "ax.set_title('Review distribution by main category')\n",
    "\n",
    "joined.main_category.value_counts().plot(kind='bar', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'All reviews': joined.main_category.value_counts(),\n",
    "}).sort_values('All reviews', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular categories by a large margin seem to be books and electronics. The least popular categories have very few reviews in our sample so the results we get from them might not be very relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(13,5))\n",
    "by_category = joined.groupby('main_category')\n",
    "\n",
    "ax.set_title('Mean review score by category')\n",
    "\n",
    "plot_groupby_error_bars(by_category.overall, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from here that products belonging to certain categories indeed tend to receive better reviews on average.\n",
    "\n",
    "We can also look at the relationship between the overall rating given in a review and the overall sentiment score of the description. We expect negative reviews to have a sentiment score closer to -1 and vice versa. The sentiment classifier we chose assigns 4 scores to each review text: positive score, negative score, neutral score and a normalized compound score. Negative, positive and neutral scores go from 0 to 1 and compound score goes from -1 (most negative) to 1 (most positive) where scores between -0.5 and 0.5 are considered neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "by_overall = joined.groupby('overall')\n",
    "\n",
    "_, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_title('Mean compound sentiment score')\n",
    "plot_groupby_error_bars(by_overall.compound_score, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our expectations were correct: negative reviews indeed have a lower sentiment score, but even the 1 star reviews do not seem to have a strongly negative connotation. Perhaps overly rude or angry reviews are removed by Amazon's staff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_title('Mean positive sentiment score')\n",
    "\n",
    "plot_groupby_error_bars(by_overall.positive_score, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_title('Mean neutral sentiment score')\n",
    "\n",
    "plot_groupby_error_bars(by_overall.neutral_score, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_title('Mean negative sentiment score')\n",
    "\n",
    "plot_groupby_error_bars(by_overall.negative_score, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 5))\n",
    "ax1.set_title('Mean compound sentiment score')\n",
    "plot_groupby_error_bars(by_category.compound_score, 1000, np.mean, ax1)\n",
    "\n",
    "ax2.set_title('Mean positive sentiment score')\n",
    "plot_groupby_error_bars(by_category.positive_score, 1000, np.mean, ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative, positive and neutral sentiment scores confirm what we saw by observing the compound score. Like with ratings, some categories such as gift cards, music, baby, toys and games have a higher compound or positive semtiment score even though none of them is very different from the others. Gift cards also has very few reviews so its score is not reliable.\n",
    "\n",
    "We verify whether an item's price is correlated to its sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "ax.set_title('Mean compound sentiment score')\n",
    "plot_groupby_error_bars(group_by_price_tier.compound_score, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more positive sentiment score doesn't correlate with a higher price.\n",
    "\n",
    "We tried to verify whether the sentiment score of the reviews of a product correlates with its sales ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "onlyranked = joined.dropna(subset=['salesRankPosition'])\n",
    "\n",
    "r = ax.hist2d(onlyranked.salesRankPosition, onlyranked.negative_score, bins=20, norm=LogNorm())\n",
    "ax.set_title('Distribution of sentiment score and sales ranking')\n",
    "ax.set_xlabel('Sales ranking')\n",
    "ax.set_ylabel('Negative sentiment score')\n",
    "fig.colorbar(r[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "img = ax.hist2d(onlyranked.salesRankPosition, onlyranked.positive_score, bins=20, norm=LogNorm())\n",
    "ax.set_title('Distribution of sentiment score and sales ranking')\n",
    "ax.set_xlabel('Sales ranking')\n",
    "ax.set_ylabel('Positive sentiment score')\n",
    "fig.colorbar(img[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "img = ax.hist2d(onlyranked.salesRankPosition, onlyranked.compound_score, bins=20, norm=LogNorm())\n",
    "ax.set_title('Distribution of sentiment score and sales ranking')\n",
    "ax.set_xlabel('Sales ranking')\n",
    "ax.set_ylabel('Compound sentiment score')\n",
    "fig.colorbar(img[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sales ranking of a product and the sentiment score of its reviews don't seem to be correlated: from the above plots we can see that the items that have the most reviews are those higher up in the sales ranking which is expected since they are more likely to appear in user searches but also that the overall distribution of the sentiment scores doesn't change with the sales ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried comparing the length of the reviews to the price tier of the items being reviewed: our theory is that customers that purchase a more expensive item are more likely to write a more detailed review. We observed that this doesn not happen when looking at the dataset as a whole but only when looking at some categories, such as electronics individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = joined[joined.main_category == 'Electronics'].groupby('price_tier').word_count\n",
    "ax = plt.subplot()\n",
    "plot_groupby_error_bars(gb, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = joined[joined.main_category == 'Home & Kitchen'].groupby('price_tier').word_count\n",
    "ax = plt.subplot()\n",
    "plot_groupby_error_bars(gb, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = joined[joined.main_category == 'Office Products'].groupby('price_tier').word_count\n",
    "ax = plt.subplot()\n",
    "plot_groupby_error_bars(gb, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = joined[joined.main_category == 'Clothing, Shoes & Jewelry'].groupby('price_tier').word_count\n",
    "ax = plt.subplot()\n",
    "plot_groupby_error_bars(gb, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = joined[joined.main_category == 'Patio, Lawn & Garden'].groupby('price_tier').word_count\n",
    "ax = plt.subplot()\n",
    "plot_groupby_error_bars(gb, 1000, np.mean, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "In the abstract for our project we planned to investigate whether factors such as a product's price or the season in which a review is written can affect the score given to a product. When analyzing the dataset we found that such correlations seem to be absent in the data and the only other feature that correlates with the review's score is the sentiment score (positive or negative) that the review's extended summary expresses. Furthermore we have discovered that in some of the categories the length of the review positively correlates with the price tier of the product, suggesting that users might write more detailed reviews for products that they spent more money on. It seems that just looking at the numbers in the data doesn't tell us too much about what we want to know and we might need to conduct further analysis on the text of the reviews or the features of the product (such as looking at what other items are related to the one being reviewed or seeing if we can predict whether a review is going to be more useful according to which words the author uses and how high the sentimental score of the review is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Direction:\n",
    "\n",
    "We struggled to find significant correlations with the price, time, salesRank factors on user reviews, as we had initially proposed. However, we became more interested in learning about how incentivization can impact how reviewers write their reviews and how products are rated. The following is a glimpse into a couple interesting leads we have to understand the influence of incentivization on review quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using keywords in incentivized reviews (i.e., \"I received xxx product for free in exchange for an honest, \n",
    "# unbiased review\"), we separate the incentivized reviews from those that are not incentivized. \n",
    "mask = joined['reviewText'].map(lambda x: ('in exchange for an unbiased review' in x) or ('in exchange for an honest' in x) or ('disclaimer' in x) or ('all opinions stated' in x))\n",
    "incentivized = joined[mask]\n",
    "non_incentivized = joined[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incentivized[incentivized['main_category'] == 'Electronics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is an example of a so-called \"unbiased review\"\n",
    "print('Incentivized Review example: ')\n",
    "incentivized.iloc[100]['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sizes of incentivized samples vs non.\n",
    "print(non_incentivized.shape)\n",
    "print(incentivized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"incentivized overall rating: \", incentivized['overall'].mean())\n",
    "print(\"non_incentivized overall rating: \", non_incentivized['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Frequency of Star Ratings of Incentivized Reviews')\n",
    "(incentivized.groupby('overall').size()/incentivized.shape[0]).plot(kind = 'bar')\n",
    "plt.show()\n",
    "print('Histogram of Review Text Sentiment Scores for Incentivized Reviews')\n",
    "incentivized['compound_score'].hist(weights = [1/incentivized.shape[0]]*incentivized.shape[0])\n",
    "plt.show()\n",
    "print('Frequency of Star Ratings of Non-Incentivized Reviews')\n",
    "\n",
    "(non_incentivized.groupby('overall').size()/non_incentivized.shape[0]).plot(kind = 'bar')\n",
    "plt.show()\n",
    "print('Histogram of Review Text Sentiment Score for Non-Incentivized Reviews')\n",
    "\n",
    "non_incentivized['compound_score'].hist(weights = [1/non_incentivized.shape[0]]*non_incentivized.shape[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, the sizes of the two sets of reviews is very different, and we do not have nearly as many for the incentivized set compared to the non-incentivized set, we can still make some conclusions on how people, who are given products for free or at a discount, write their reviews. Using the vader sentiment analyzer, we can see that incentivized reviews are much more positive that non-incentivized. In addition, people who are given products for free/discounted give more positive ratings and less 1 or 2-star ratings. Our plan to further analyze this phenomenon is detailed in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incentivized.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_incentivized.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "no_zero = joined[(joined['positive_score'] == 0.0) | (joined['compound_score'] == 0.0) | (joined['negative_score'] == 0.0) | (joined['neutral_score'] == 0.0)]\n",
    "\n",
    "print('Histogram of Review Text compound Sentiment Scores')\n",
    "no_zero['compound_score'].hist(weights = [1/no_zero.shape[0]]*no_zero.shape[0], bins = 100)\n",
    "plt.show()\n",
    "\n",
    "print('Histogram of Review Text positive Sentiment Scores')\n",
    "no_zero['positive_score'].hist(weights = [1/no_zero.shape[0]]*no_zero.shape[0], bins = 100)\n",
    "plt.show()\n",
    "\n",
    "print('Histogram of Review Text negative Sentiment Scores')\n",
    "no_zero['negative_score'].hist(weights = [1/no_zero.shape[0]]*no_zero.shape[0], bins = 100)\n",
    "plt.show()\n",
    "\n",
    "print('Histogram of Review Text neutral Sentiment Scores')\n",
    "no_zero['neutral_score'].hist(weights = [1/no_zero.shape[0]]*no_zero.shape[0], bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bucket the reviews, tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.groupby('overall').tokenized_text.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ada]",
   "language": "python",
   "name": "Python [ada]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
